{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "jaxLenet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOhQ+e1LPRmEKvh3wPtPMzB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Songloading/Image-Classfication-Tasks/blob/main/jaxLenet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxFndTvfWCWW"
      },
      "source": [
        "import time\n",
        "import itertools\n",
        "\n",
        "import numpy.random as npr\n",
        "\n",
        "import jax.numpy as np\n",
        "from jax import jit, grad, random\n",
        "from jax.experimental import optimizers\n",
        "from jax.experimental import stax\n",
        "from jax.experimental.stax import Dense, Relu, LogSoftmax, Conv, MaxPool, Flatten\n",
        "# from examples import dataset"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXyk35wPXQAh"
      },
      "source": [
        "## This block is for data loading (MNIST)\n",
        "import array\n",
        "import gzip\n",
        "import os\n",
        "from os import path\n",
        "import struct\n",
        "import urllib.request\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "_DATA = \"/tmp/jax_example_data/\"\n",
        "\n",
        "\n",
        "def _download(url, filename):\n",
        "  \"\"\"Download a url to a file in the JAX data temp directory.\"\"\"\n",
        "  if not path.exists(_DATA):\n",
        "    os.makedirs(_DATA)\n",
        "  out_file = path.join(_DATA, filename)\n",
        "  if not path.isfile(out_file):\n",
        "    urllib.request.urlretrieve(url, out_file)\n",
        "    print(\"downloaded {} to {}\".format(url, _DATA))\n",
        "\n",
        "\n",
        "def _partial_flatten(x):\n",
        "  \"\"\"Flatten all but the first dimension of an ndarray.\"\"\"\n",
        "  return np.reshape(x, (x.shape[0], -1))\n",
        "\n",
        "\n",
        "def _one_hot(x, k, dtype=np.float32):\n",
        "  \"\"\"Create a one-hot encoding of x of size k.\"\"\"\n",
        "  return np.array(x[:, None] == np.arange(k), dtype)\n",
        "\n",
        "\n",
        "def mnist_raw():\n",
        "  \"\"\"Download and parse the raw MNIST dataset.\"\"\"\n",
        "  # CVDF mirror of http://yann.lecun.com/exdb/mnist/\n",
        "  base_url = \"https://storage.googleapis.com/cvdf-datasets/mnist/\"\n",
        "\n",
        "  def parse_labels(filename):\n",
        "    with gzip.open(filename, \"rb\") as fh:\n",
        "      _ = struct.unpack(\">II\", fh.read(8))\n",
        "      return np.array(array.array(\"B\", fh.read()), dtype=np.uint8)\n",
        "\n",
        "  def parse_images(filename):\n",
        "    with gzip.open(filename, \"rb\") as fh:\n",
        "      _, num_data, rows, cols = struct.unpack(\">IIII\", fh.read(16))\n",
        "      return np.array(array.array(\"B\", fh.read()),\n",
        "                      dtype=np.uint8).reshape(num_data, rows, cols)\n",
        "\n",
        "  for filename in [\"train-images-idx3-ubyte.gz\", \"train-labels-idx1-ubyte.gz\",\n",
        "                   \"t10k-images-idx3-ubyte.gz\", \"t10k-labels-idx1-ubyte.gz\"]:\n",
        "    _download(base_url + filename, filename)\n",
        "\n",
        "  train_images = parse_images(path.join(_DATA, \"train-images-idx3-ubyte.gz\"))\n",
        "  train_labels = parse_labels(path.join(_DATA, \"train-labels-idx1-ubyte.gz\"))\n",
        "  test_images = parse_images(path.join(_DATA, \"t10k-images-idx3-ubyte.gz\"))\n",
        "  test_labels = parse_labels(path.join(_DATA, \"t10k-labels-idx1-ubyte.gz\"))\n",
        "\n",
        "  return train_images, train_labels, test_images, test_labels\n",
        "\n",
        "\n",
        "def mnist(permute_train=False):\n",
        "  \"\"\"Download, parse and process MNIST data to unit scale and one-hot labels.\"\"\"\n",
        "  train_images, train_labels, test_images, test_labels = mnist_raw()\n",
        "\n",
        "  train_images = _partial_flatten(train_images) / np.float32(255.)\n",
        "  test_images = _partial_flatten(test_images) / np.float32(255.)\n",
        "  train_labels = _one_hot(train_labels, 10)\n",
        "  test_labels = _one_hot(test_labels, 10)\n",
        "\n",
        "  if permute_train:\n",
        "    perm = np.random.RandomState(0).permutation(train_images.shape[0])\n",
        "    train_images = train_images[perm]\n",
        "    train_labels = train_labels[perm]\n",
        "\n",
        "  return train_images, train_labels, test_images, test_labels"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_-UkPpgKIKD"
      },
      "source": [
        "# some useful materials:\n",
        "# http://gcucurull.github.io/deep-learning/2020/04/20/jax-graph-neural-networks/\n",
        "# https://jax.readthedocs.io/en/latest/_modules/jax/experimental/stax.html\n",
        "# https://jax.readthedocs.io/en/latest/jax.experimental.stax.html"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylDhNFH_WGxa"
      },
      "source": [
        "def loss(params, batch):\n",
        "    inputs, targets = batch\n",
        "    preds = predict(params, inputs)\n",
        "    return -np.mean(np.sum(preds * targets, axis=1))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HeAjngaWZKn"
      },
      "source": [
        "def accuracy(params, batch):\n",
        "    inputs, targets = batch\n",
        "    target_class = np.argmax(targets, axis=1)\n",
        "    predicted_class = np.argmax(predict(params, inputs), axis=1)\n",
        "    return np.mean(predicted_class == target_class)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jitWTPqVWuUM"
      },
      "source": [
        "# init_fun: initilization function for the parameters of the layer.\n",
        "# apply_fun: forward computation function\n",
        "## \"The init_fun is used to initialize network parameters and the apply_fun takes parameters and inputs to produce outputs.\"\n",
        "init_random_params, predict = stax.serial(\n",
        "    Conv(out_chan=6, filter_shape=(5, 5), strides=(1, 1), padding=\"VALID\"), Relu,\n",
        "    MaxPool(window_shape=(2, 2), padding=\"VALID\", spec=\"NCHW\"),\n",
        "    Conv(out_chan=16, filter_shape=(5, 5), strides=(1, 1), padding=\"VALID\"), Relu,\n",
        "    MaxPool(window_shape=(2, 2), padding=\"VALID\", spec=\"NCHW\"),\n",
        "    Flatten,\n",
        "    Dense(120), Relu,\n",
        "    Dense(84), Relu,\n",
        "    Dense(10), LogSoftmax)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-vMGBRTN1Ap",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49fb818b-b94c-49da-c7e7-10f90138e28b"
      },
      "source": [
        "rng = random.PRNGKey(0) ## explicitly generate state key\n",
        "\n",
        "step_size = 0.001\n",
        "num_epochs = 10\n",
        "batch_size = 128\n",
        "momentum_mass = 0.9\n",
        "\n",
        "\n",
        "train_images, train_labels, test_images, test_labels = mnist()\n",
        "print(\"Shape Before:\" + str(train_images.shape))\n",
        "num_train = train_images.shape[0]\n",
        "num_complete_batches, leftover = divmod(num_train, batch_size) #divmod returns quotient and remainder of first param/ 2nd param\n",
        "num_batches = num_complete_batches + bool(leftover)\n",
        "\n",
        "train_images = np.asarray(train_images.reshape(-1, 1, 28, 28))\n",
        "test_images = np.asarray(test_images.reshape(-1, 1, 28, 28))\n",
        "\n",
        "print(train_images.shape, train_labels.shape)\n",
        "print(test_images.shape, test_labels.shape)\n",
        "print(train_images.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape Before:(60000, 784)\n",
            "(60000, 1, 28, 28) (60000, 10)\n",
            "(10000, 1, 28, 28) (10000, 10)\n",
            "(60000, 1, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7N7J1ltY39D"
      },
      "source": [
        " def data_stream():\n",
        "        rng = npr.RandomState(0)\n",
        "        while True:\n",
        "            perm = rng.permutation(num_train)\n",
        "            for i in range(num_batches):\n",
        "                batch_idx = perm[i * batch_size:(i + 1) * batch_size]\n",
        "                yield train_images[batch_idx], train_labels[batch_idx]\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emxfvlCAaLlA"
      },
      "source": [
        "batches = data_stream()\n",
        "opt_init, opt_update, get_params = optimizers.sgd(step_size)\n",
        "# Every optimizer is modeled as an (init_fun, update_fun, get_params) triple of functions. \n",
        "# The init_fun is used to initialize the optimizer state, which could include things like momentum variables\n",
        "# The update_fun accepts a gradient and an optimizer state to produce a new optimizer state. \n",
        "# The get_params function extracts the current iterate (i.e. the current parameters) from the optimizer state."
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-KzzYQmbzyT"
      },
      "source": [
        "@jit\n",
        "def update(i, opt_state, batch):\n",
        "      params = get_params(opt_state)\n",
        "      return opt_update(i, grad(loss)(params, batch), opt_state)  #https://jax.readthedocs.io/en/latest/jax.html#jax.grad"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1kbV-qhb2IH"
      },
      "source": [
        " _, init_params = init_random_params(rng, (-1, 1, 28, 28))\n",
        "opt_state = opt_init(init_params)\n",
        "itercount = itertools.count()\n",
        "\n",
        "print(\"\\nStarting training...\")\n",
        "for epoch in range(num_epochs):\n",
        "    start_time = time.time()\n",
        "    for _ in range(num_batches):\n",
        "        opt_state = update(next(itercount), opt_state, next(batches))\n",
        "    epoch_time = time.time() - start_time\n",
        "\n",
        "    params = get_params(opt_state)\n",
        "    train_acc = accuracy(params, (train_images, train_labels))\n",
        "    test_acc = accuracy(params, (test_images, test_labels))\n",
        "    print(\"Epoch {} in {:0.2f} sec\".format(epoch, epoch_time))\n",
        "    print(\"Training set accuracy {}\".format(train_acc))\n",
        "    print(\"Test set accuracy {}\".format(test_acc))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}